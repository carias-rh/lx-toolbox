#!/usr/local/bin/python3
"""
First implementation for processing SNOW tickets that are specifically about typos
in Student Guides using Selenium and local AI (Ollama).
"""

import os
import re
import subprocess
import time
import json
from selenium import webdriver
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.action_chains import ActionChains

import requests
import logging
from urllib.parse import quote

# -------------------------------------------------------------------
# Configurable constants for local paths, etc.
# -------------------------------------------------------------------
LOCAL_CLONE_DIRECTORY = "{{ playbook_dir }}/files/"
GUIDE_SUBDIR = "content"
OLLAMA_COMMAND = "/usr/local/bin/ollama"  # Adjust if your Ollama binary is named differently
CHROME_DEBUG_PORT = 9123    # Example local Chrome debugger port for your session
CHROME_USER_DATA_DIR = "{{ ansible_env.HOME}}/.config/google-chrome/snow-typos"

counter = 1
# Prints the current step
def step(step_str, patience=1):
    global counter
    print(f"Step {counter}: {step_str}")
    print('-' * 40)
    counter += 1
    time.sleep(patience)

# -------------------------------------------------------------------
# Browser session helpers
# -------------------------------------------------------------------
def open_profile():
    """
    Opens a new Google Chrome session with remote debugging enabled,
    using the designated user data directory.
    """
    os.popen('google-chrome --remote-debugging-port=' + str(CHROME_DEBUG_PORT) +
             ' --user-data-dir=' + CHROME_USER_DATA_DIR + ' &')

def check_running_session():
    """
    Checks if a Google Chrome session is already running by looking for the user data directory
    and the designated debugging port.
    Returns the PID if found, or 0 otherwise.
    """
    pid = os.popen("ps -ef | grep '" + CHROME_USER_DATA_DIR +
                   "' | grep " + str(CHROME_DEBUG_PORT) +
                   " | grep -v grep | head -n1 | awk '{print $2}'").read().strip()
    if pid:
        return int(pid)
    else:
        return 0

# -------------------------------------------------------------------
# Function to set up the Selenium driver for Chrome
# -------------------------------------------------------------------
def get_chrome_driver() -> webdriver.Chrome:
    """
    Returns a Selenium Chrome WebDriver configured to use the
    remote debugging port and user data directory.
    """
    options = webdriver.ChromeOptions()
    options.add_argument("--ignore-certificate-errors")
    options.add_argument("--window-size=1600,1200")
    # Attach to our debug port and user data directory
    options.add_experimental_option("debuggerAddress", f"localhost:{CHROME_DEBUG_PORT}")
    options.add_argument(f"--user-data-dir={CHROME_USER_DATA_DIR}")

    try:
        driver = webdriver.Chrome(options=options)
        return driver
    except Exception as e:
        print(f"[ERROR] Unable to start Chrome driver: {e}")
        raise


# -------------------------------------------------------------------
# Example function to call Ollama locally with your query/prompt
# -------------------------------------------------------------------
# You can change the model to one available on your system.
OLLAMA_MODEL = "granite3.1-dense:8b"
OLLAMA_MODEL = "gabegoodhart/granite3.2-preview:8b"
#OLLAMA_MODEL = "llama3.2:latest"


def askOllama(prompt: str) -> str:
    """
    Runs Ollama locally with the given prompt and returns the response text.
    Make sure 'ollama' is installed on your system and in PATH.
    """
    try:
        # Use 'ollama run <model> "<prompt>"'
        result = subprocess.run(
            [OLLAMA_COMMAND, "run", OLLAMA_MODEL, prompt],
            capture_output=True,
            text=True
        )
        return result.stdout.strip()
    except Exception as e:
        print(f"[ERROR] Could not run Ollama: {e}")
        return ""


def ask_gpt4_mini(prompt: str) -> str:
    """
    Calls the GPT-4 Mini API with the given prompt and returns the response.
    Uses the API key and URL from the environment variables GPT4_MINI_API_KEY and GPT4_MINI_API_URL.
    """
    import os
    import requests

    api_key = os.getenv("OPENAI_API_KEY")
    api_url = "https://api.openai.com/v1/chat/completions"
    if not api_key or not api_url:
        print("[ERROR] GPT4_MINI_API_KEY or GPT4_MINI_API_URL environment variable not set.")
        return ""
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "gpt-4o-mini",
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 500,
        "temperature": 0.7,
        "top_p": 1
    }
    try:
        response = requests.post(api_url, headers=headers, json=payload)
        response.raise_for_status()
        result = response.json()
        # Adjust the following line if the returned JSON structure differs.
        return result.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
    except Exception as e:
        print(f"[ERROR] GPT-4o-mini API request failed: {e}")
        return ""


def switch_to_iframe(driver):
    driver.switch_to.default_content()
    macroponent = WebDriverWait(driver, 3).until(
        EC.presence_of_element_located((By.XPATH, '//*[starts-with(local-name(), "macro")]'))
    )
    shadow_root = driver.execute_script('return arguments[0].shadowRoot', macroponent)
    iframe = shadow_root.find_element(By.CSS_SELECTOR, 'iframe#gsft_main')
    WebDriverWait(driver, 3).until(EC.frame_to_be_available_and_switch_to_it(iframe))


# -------------------------------------------------------------------
# Cookie, login and navigation helpers (integrated from operate-lab.py.j2)
# -------------------------------------------------------------------
def accept_cookies(driver):
    """
    Clicks the cookie accept button and refreshes the page.
    """
    try:
        WebDriverWait(driver, 3).until(
            EC.element_to_be_clickable((By.XPATH, "//a[@class='call'][text()='Agree and proceed with standard settings']"))
        ).click()
        driver.refresh()
    except Exception as e:
        driver.refresh()
        print("[WARNING] accept_cookies failed:", e)

def check_cookies(driver):
    """
    Checks if the cookie consent iframe is present and accepts cookies.
    """
    try:
        WebDriverWait(driver, 2).until(
            EC.frame_to_be_available_and_switch_to_it((By.XPATH, '//iframe[@title="TrustArc Cookie Consent Manager"]'))
        )
        accept_cookies(driver)
        driver.switch_to.default_content()
    except Exception:
        pass

def login_rol(driver):
    step("Login into ROL platform")
    try:
        check_cookies(driver)
        WebDriverWait(driver, 10).until(EC.element_to_be_clickable(
            (By.XPATH, "/html/body/div[1]/main/div/div/div[1]/div[2]/div[2]/div/section[1]/form/div[1]/input"))).send_keys("{{ rh_username }}@redhat.com")
        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="login-show-step2"]'))).click()

        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="rh-sso-flow"]'))).click()

        # RH SSO
        WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="username"]'))).send_keys("{{ username }}")
        WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="password"]'))).send_keys(str("{{ pin }}").replace('\n', '') + str(os.popen("curl -sL https://sso-rh-login-lx-snow.apps.tools-na100.dev.ole.redhat.com/get_otp").read().replace('\n', '')))
        WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="submit"]'))).click()
    except:
        print("Login failed")


def login_snow(driver):
    """
    Logs into the course website based on the lab_environment setting.
    The values for credentials should be passed in from Ansible.
    """
    step("Login into RHLS production environment")
    try:

        # RH SSO
        WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="username"]'))).send_keys("{{ username }}")
        WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="password"]'))).send_keys(str("{{ pin }}").replace('\n', '') + str(os.popen("curl -sL https://sso-rh-login-lx-snow.apps.tools-na100.dev.ole.redhat.com/get_otp").read().replace('\n', '')))
        WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="submit"]'))).click()
    except:
        print("Login failed")

def jira_login(driver):
    try:
        driver.get("https://issues.redhat.com/projects/PTL/issues")
        time.sleep(5)
        WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/header/nav/div/div[3]/ul/li[3]/a'))).click()
        time.sleep(10)

        check_cookies(driver)
        WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="username-verification"]'))).send_keys("{{ username }}" + "@redhat.com")
        WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="login-show-step2"]'))).click()
        WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="rh-sso-flow"]'))).click()
        time.sleep(5)
        driver.get("https://issues.redhat.com/projects/PTL/issues")
    except:
        print("An exception occurred during jira login")

def wait_for_site_to_be_ready():
    try:
        check_cookies(driver)
        print("Site is ready")
    except Exception as e:
        check_cookies(driver)
        print("[ERROR] Login failed:", e)



def select_lab_environment_tab(driver, tab_name):
    """
    Selects the appropriate tab on the course page.
    """
    if tab_name == "index":
        tab_id = "1"
    elif tab_name == "course":
        tab_id = "2"
    elif tab_name == "lab":
        tab_id = "8"
    try:
        WebDriverWait(driver, 60).until(
            EC.element_to_be_clickable((By.XPATH, f'//*[@id="course-tabs-tab-{tab_id}"]'))
        ).click()
        time.sleep(0.1)
        lab_environment_tab_status = WebDriverWait(driver, 30).until(
            EC.element_to_be_clickable((By.XPATH, f'//*[@id="course-tabs-tab-{tab_id}"]'))
        ).get_attribute("aria-selected")
        if lab_environment_tab_status != "true":
            time.sleep(0.1)
            select_lab_environment_tab(driver, tab_name)
    except:
        print("[WARNING] Lab environment tab not selected successfully. Retrying...")
        check_cookies(driver)
        time.sleep(2)
        select_lab_environment_tab(driver, tab_name)


# -------------------------------------------------------------------
# Function to classify a SNOW ticket using an LLM
# -------------------------------------------------------------------
def classify_ticket_llm(description: str) -> dict:
    """
    Classifies a SNOW ticket using an LLM, returning a dict like:
    {
      "student_feedback": str,
      "most_defining_issue_keyword": list[str],  # List of 3 keywords
      "is_content_issue_ticket": bool,
      "is_environment_issue": bool,
      "confidence": float,
      "summary": str
    }
    """
    step("Classifying ticket using LLM")

    json_example = '{"student_feedback":"", "most_defining_issue_keyword":["md5sum", "output", "command"], "is_content_issue_ticket":true,"is_environment_issue":false, "confidence":0.9,"summary":"The md5sum command drops a different output than the one expected."}'
    prompt = f"""
Classify the user's feedback regarding a Red Hat Training course, a typo can be a mismatch or inconsistency between the user's complaint and the text in the guide. Return JSON with fields:
- student_feedback (the user's feedback)
- most_defining_issue_keyword (a list of 3 substantive/names words such as 'ansible.builtin.lineinfile' (not verbs or adjectives) from the student_feedback that are the most unique and less generic)
- is_content_issue_ticket (true/false)
- is_environment_issue (true/false)
- confidence (a float from 0.0 to 1.0)
- summary (in a short sentence)

User feedback:
\"\"\"{description}\"\"\"

Reply in JSON only, no extra text.
For example:
{json_example}
"""
    
    global classifying_response
    #classifying_response = ask_gpt4_mini(prompt)
    classifying_response = askOllama(prompt)
    print("[GPT4-mini response regarding typos]:\n", classifying_response)
    # Then parse JSON via Python. Temporary fallback if there's an error:
    try:
        return json.loads(classifying_response)
    except:
        print("[ERROR] Could not parse JSON from LLM. Full response:", classifying_response)
        return {
            "is_content_issue_ticket": False,
            "is_environment_issue": False,
            "confidence": 0.0,
            "summary": "",
            "most_defining_issue_keyword": []
        }


# -------------------------------------------------------------------
# Function to ensure that the course repository is available
# -------------------------------------------------------------------
def ensure_course_repo(course_id: str) -> str:
    """
    Ensures that the repository for the specified course is cloned.
    The repository URL is constructed as:
       git@github.com:RedHatTraining/<base_course>.git
    where <base_course> is extracted from course_id.
    If the repository is not present in LOCAL_CLONE_DIRECTORY, it is cloned.
    If it exists, a 'git pull' is performed.
    Returns the repository directory path.
    """
    step("Ensuring course repository is available")
    repo_dir = os.path.join(LOCAL_CLONE_DIRECTORY, course_id)
    repo_url = f"git@github.com:RedHatTraining/{course_id}.git"
    if not os.path.exists(repo_dir):
        print(f"[INFO] Repository not found at {repo_dir}. Cloning from {repo_url} ...")
        clone_cmd = f"git clone {repo_url} {repo_dir}"
        result = os.system(clone_cmd)
        if result != 0:
            print(f"[ERROR] Failed to clone repository: {repo_url}")
    else:
        print(f"[INFO] Repository found at {repo_dir}. Pulling latest changes...")
        pull_cmd = f"cd {repo_dir} && git pull"
        os.system(pull_cmd)
    return repo_dir


# -------------------------------------------------------------------
# Function to extract the lab script name from the course page
# -------------------------------------------------------------------
def get_section_info(driver, course_url: str) -> str:
    """
    Navigates to the course URL, performs login if necessary,
    and extracts the lab start command from the page.
    Returns the lab script name specified in a command such as 'lab start <script name>'.
    """
    step("Extracting relevant information from section")
    try:
        driver.execute_script("window.open()");
        driver.switch_to.window(driver.window_handles[-1]);
        driver.get(course_url)
        login_rol(driver)
        # Optionally, if login is enforced here, call:
        # login(driver, lab_environment, rh_username, username, pin, github_username, github_password)
        # You can pass the required credentials from Ansible variables.
        #login(driver)

        time.sleep(5)  # Allow time for the page to load completely
        
        # If your course page has tabs, you might need to select the "course" tab
        select_lab_environment_tab(driver, "course")

        # It is a guided exercise
        relevant_section_info = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.XPATH, "//h3/a[not(contains(@id, 'objectives'))]//.. | //*[contains(text(), 'lab start')]"))
        ).text

        print(f"[INFO] Found relevant section keyword: {relevant_section_info}")
        return relevant_section_info

    except Exception as e:
        print(f"[ERROR] Could not retrieve lab start script name from {course_url}: {e}")
        return ""


# -------------------------------------------------------------------
# Function to fetch relevant text from the local course repository
# -------------------------------------------------------------------
def fetch_local_guide_text(section_info: str, repo_dir: str = None) -> str:
    """
    Fetches the relevant guide text from the course repository.
    If repo_dir is not provided, it is constructed from the course_id.
    Uses lab_script_name to grep for the correct adoc file.
    """

    if repo_dir is not None and section_info != "":
        file_dir = f"grep -ri '{section_info}' {repo_dir}/{GUIDE_SUBDIR} | grep -E 'ge.adoc|lecture.adoc|review.adoc|lab.adoc' | head -n1 | cut -d ':' -f1"
    
        try:
            content_file = subprocess.check_output(file_dir, shell=True).decode().strip()
            print(f"[INFO] Content file path: {content_file}")
            with open(content_file) as file:
                content_file = file.read().strip()
        except Exception as e:
            print(f"[ERROR] Could open file {content_file}: {e}")
            return ""            
        return content_file.strip()
    else:
        print("[INFO] Not enough information to fetch local guide text.")
        return ""


def analyze_content_issue(user_issue: str, guide_text: str) -> str:
    """
    Analyzes a potential content issue by comparing user feedback with guide text.
    
    Args:
        user_issue: The user's reported issue/feedback
        guide_text: Relevant excerpt from the guide
        
    Returns:
        str: JSON response from LLM analysis
    """
    json_example = '''{
            "analysis": "think in this value step by step, compare the student's feedback with the guide text, and provide a detailed analysis of the issue",",
            "is_valid_issue": true/false,
            "content_issue_location": "location/step where the content issue appears",
            "suggested_correction": "a brief suggestion for correction if applicable; otherwise an empty string",
            "confidence": "a float value between 0 and 1 indicating your confidence",
            "summary": "a short summary of your analysis"
            }'''

    prompt_text = f"""
We have a student who reported an issue within the guide text. The student's feedback is:
<student_feedback>
{user_issue}
</student_feedback>

Below is an excerpt of the guide section:
<guide_text>
{guide_text}
</guide_text>

Compare the student's feedback with the guide text, and provide a detailed analysis of the issue.
Your analysis must consider only the instructions, theory and commands that are part of the text. 
Remove from the response in the JSON any reference to titles or headings, as I already have that information.

Return your analysis in exactly the following JSON format without any extra text:
<json_example>
{json_example}
</json_example>

Do not include any explanations or markdown formatting outside the JSON object.
"""
    global analysis_response
    #analysis_response = ask_gpt4_mini(prompt_text)
    analysis_response = askOllama(prompt_text)
    return analysis_response



def get_snow_info(driver, snow_id):
    driver.get('https://redhat.service-now.com/surl.do?n=' + snow_id + '')
    time.sleep(10)
    switch_to_iframe(driver)

    # Get description
    description = driver.find_element("xpath", '//*[@id="sys_original.x_redha_red_hat_tr_x_red_hat_training.description"]').get_attribute('value')

    # Get issue info
    issue = re.search(r"Description:\s*(.*?)\s*Copyright", description, re.DOTALL).group(1).strip()
    course = re.findall("Course:.*", description)[0].split(":  ")[1].upper().replace(" ", "")
    version = re.findall("Version:.*", description)[0].split(":  ")[1]
    url = re.findall("URL:.*", description)[0].split(":  ")[1]
    if "role.rhu.redhat.com/rol-rhu" in url:
        url = url.replace("role.rhu.redhat.com/rol-rhu", "rol.redhat.com/rol")

    # Get chapter and section
    try:
        chapter = re.findall("ch[0-9][0-9]", url)[0].split("ch")[1]
    except:
        chapter= ""
    try:
        section = re.findall("s[0-9][0-9]", url)[0].split("s")[1]
    except:
        section = ""
    title = re.findall("Section Title:.*", description)[0].split(":  ")[1]
    rhnid = re.findall("User Name:.*", description)[0].split(":  ")[1]

    snow_info = {
        "snow_id": snow_id,
        "Description": issue,
        "Course": course,
        "Version": version,
        "URL": url,
        "Chapter": chapter,
        "Section": section,
        "Title": title,
        "RHNID": rhnid,
    }
    driver.refresh()
    return snow_info

def select_dropdown(element, input):
    element.send_keys(Keys.CONTROL + "a")
    element.send_keys(Keys.DELETE)
    element.send_keys(input)
    element.send_keys(Keys.TAB)

def switch_to_tab(driver, tabname):
    WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, f'//ul[@role="tablist"]//strong[text()="{tabname}"]'))).click()


def create_jira(driver, snow_info, analysis_response):

    driver.get("https://issues.redhat.com/projects/PTL/issues")
    time.sleep(5)

    # Click Create
    WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="create_link"]'))).click()

    # Select Text mode
    WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="description-wiki-edit"]/nav/div/div/ul/li[2]/button'))).click()

    # Fill in Summary
    WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="summary"]'))).send_keys(f'{snow_info["Course"]}: ch{snow_info["Chapter"]}s{snow_info["Section"]} -  - {snow_info["snow_id"]}')

    # Add Description
    color1 = '{color:#0747a6}'
    color2 = '{color}'
    description = f"""
        h3. {color1}*Please fill in the following information:*{color2}
    ----
    |*URL:*|[ch{snow_info["Chapter"]}s{snow_info["Section"]} |{snow_info["URL"]}]|
    |*Reporter RHNID:*| {snow_info["RHNID"]} |
    |*Section title:*|{snow_info["Title"]}|
    |*Language*:| English |

    *Issue description*

    {snow_info["Description"]}

    *Steps to reproduce:*

    *Workaround:*
    {analysis_response.get("suggested_correction", "")}

    *Expected result:*"""

    # Add description
    WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="description"]'))).clear()
    WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="description"]'))).send_keys(description)

    # Select Visual mode back again
    WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="description-wiki-edit"]/nav/div/div/ul/li[1]/button'))).click()

    # Select Component (course)
    WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="components-textarea"]'))).send_keys(snow_info["Course"])

    # Add chapter and section
    WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="customfield_12316549"]'))).send_keys(snow_info['Chapter'])

    # Select version
    version = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="versions-textarea"]')))
    version.send_keys(Keys.HOME)

    # Change to priority tab and change priority
    switch_to_tab(driver, 'Priority')
    priority_dropdown = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="priority-field"]')))
    select_dropdown(priority_dropdown, "Minor")
    switch_to_tab(driver, 'Field Tab')


def search_jira_ticket(driver, snow_info):
    """
    Searches for similar Jira tickets by constructing a customized URL.
    It uses the analysis_response_json info to query the LLM and extract the single most
    unique and defining word that best captures the core issue. This word is then used in 
    the JQL query to find previous tickets with the same issue.
    
    The URL format should be that of a Jira search, not a specific issue.
    """
    # Construct a prompt to extract the single most unique and defining word from the analysis details.
    prompt =  (
        f"You are an expert technical keyword extractor."
        f"From this information, identify the single most defining and significant technical term that encapsulate the core issue reported."
        f"Consider any technical namesâ€”this can include lab script names (like 'declarative-review'), directory names (/home/student/DO280), OpenShift deployment names, Ansible modules, specific commands, or any other technical identifier mentioned."
        f"Output only ONE term with no additional explanation from the student's feedback. Just ONE keyword, no quotes, no explanation, no nothing else."
        f"<feedback> {snow_info['Description']} </feedback>"

    )

    llm_response = askOllama(prompt)
    extracted_keyword = llm_response.strip()
    print(f"[INFO] LLM extracted keyword: {extracted_keyword}")
    
    # Use the extracted keyword if available; otherwise, fallback to the initial keyword.
    final_keyword = extracted_keyword if extracted_keyword else initial_keyword

    # Get the course value from snow_info to be used as the component.
    course = snow_info.get("Course", "")

    # Build the JQL query including unresolved tickets.
    jql = f'project = PTL AND resolution = Unresolved AND component = "{course}" AND text ~ "{final_keyword}" ORDER BY priority DESC, updated DESC'
    encoded_jql = quote(jql)
    search_url = f"https://issues.redhat.com/issues/?jql={encoded_jql}"

    print(f"[INFO] Jira search URL: {search_url}")
    driver.get(search_url)
    time.sleep(5)  # Allow time for the search results page to load.


# -------------------------------------------------------------------
# Put everything together in a main workflow for a single SNOW ticket
# -------------------------------------------------------------------
def handle_snow_ticket(driver: webdriver.Chrome, snow_info: dict):
    """
    Processes a SNOW ticket by:
    3. Checking via LLM if it's a typo ticket.
    4. If so, ensuring the course repository is available, fetching the lab start script name
       from the course page (using the URL in the ticket), and then fetching the guide text,
       then invoking further LLM analysis.
    """

    # 1. Classify the ticket
    data = classify_ticket_llm(snow_info["Description"])
    if not data.get("is_content_issue_ticket", False):
        print(f"[INFO] This SNOW ticket {snow_info['snow_id']} doesn't appear to be a simple 'typo' issue.")
        return

    print(f"[INFO] SNOW ticket {snow_info['snow_id']} is recognized as a 'typo' feedback ticket.")

    # 3. Ensure the repository is available
    repo_dir = ensure_course_repo(snow_info["Course"].lower())

    # 4. Retrieve some info from the course page to match with the local guide text
    if snow_info["URL"] != "":
        section_info = get_section_info(driver, snow_info["URL"])

    # 5. Fetch local guide text using the guide info
    local_guide_text = ""
    if section_info != "":
        local_guide_text = fetch_local_guide_text(section_info, repo_dir)
    else:
        print("[INFO] No course ID or lab script name found in the SNOW ticket.")
        return
    
    if data.get("is_content_issue_ticket", False):
        print(f"[INFO] This SNOW ticket {snow_info['snow_id']} is recognized as a 'content' issue feedback ticket.")
    else:
        print(f"[INFO] This SNOW ticket {snow_info['snow_id']} doesn't appear to be a simple 'content' issue.")
        return

    # 6. Perform a grep search for the most defining issue keyword in the local guide text or pass the whole text to the LLM
    most_defining_issue_keyword = data.get("most_defining_issue_keyword", "")
    print(f"[INFO] Most defining issue keyword: {most_defining_issue_keyword}")
    grep_result = ""
    if most_defining_issue_keyword:
        grep_results = []
        for keyword in most_defining_issue_keyword:
            if keyword != "":
                try:
                    result = subprocess.run(
                        ["grep", "-i", keyword],
                        input=local_guide_text,
                        text=True,
                        capture_output=True
                    ).stdout
                    grep_results.append(result)
                except subprocess.CalledProcessError as e:
                    print(f"[ERROR] Grep command failed for keyword '{keyword}': {e}")
        guide_text = "\n".join(grep_results)
    else:
        guide_text = local_guide_text
        print("[INFO] No defining issue keyword found in the LLM response.")

    analysis_response = analyze_content_issue(snow_info["Description"], guide_text)
    print("[LLM response]:\n", analysis_response)


    # Parse the analysis response
    analysis_response_json = json.loads(analysis_response)

    # 7. Add work note in the SNOW ticket with the summary of the analysis
    try:
        # Create a work note with the summary
        work_note = f"Summary of the analysis:\n"
        work_note += f"{analysis_response_json.get('summary', 'No summary available')}\n"

        # Add the work note to the SNOW ticket
        driver.switch_to.window(driver.window_handles[0])
        driver.refresh()
        time.sleep(5)
        switch_to_iframe(driver)
        WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="x_redha_red_hat_tr_x_red_hat_training.work_notes"]'))).send_keys(work_note)
        
    except json.JSONDecodeError as e:
        print(f"[ERROR] Failed to parse analysis response as JSON: {e}")
    except Exception as e:
        print(f"[ERROR] Failed to add work note to SNOW ticket: {e}")

    # 8. Add a work note in the SNOW ticket to reply the student's feedback


    # 9. Create a Jira ticket
    if analysis_response_json.get("is_valid_issue", False):
        # Switch to new tab
        # Move to the latest tab before opening a new one
        driver.switch_to.window(driver.window_handles[-1])
        driver.execute_script("window.open('');")
        driver.switch_to.window(driver.window_handles[-1])
        jira_login(driver)

        # 9.1 Search for similar Jira tickets
        search_jira_ticket(driver, snow_info)

        # 9.2 Create a Jira ticket in a new tab
        driver.execute_script("window.open('');")
        driver.switch_to.window(driver.window_handles[-1])
        create_jira(driver, snow_info, analysis_response_json)


    
    return


def get_ticket_ids(driver) -> list:
    """
    Returns a list of ticket IDs from the ServiceNow ticket list.
    It first checks if there are tickets on the page. If tickets are available,
    it finds all anchor elements within the ticket table that have the class
    'linked formlink' and extracts their text (the ticket IDs).
    """
    ticket_ids = []
    try:
        switch_to_iframe(driver)
        # Check if there are any tickets available
        tickets_in_line = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.XPATH, '//*[@id="x_redha_red_hat_tr_x_red_hat_training"]/div[1]'))
        ).text

        if tickets_in_line.strip() == 'No records to display':
            logging.info("No tickets to process for resolution.")
            return ticket_ids

        # Locate the ticket table body
        table_body = WebDriverWait(driver, 3).until(
            EC.presence_of_element_located((By.XPATH, '//tbody[@class="list2_body -sticky-group-headers"]'))
        )

        # Extract each ticket link (anchor) with the specified class.
        ticket_elements = table_body.find_elements(By.XPATH, './/a[@class="linked formlink"]')
        for ticket in ticket_elements:
            ticket_id = ticket.text.strip()
            if ticket_id:
                ticket_ids.append(ticket_id)
    except Exception as e:
        logging.error(f"Error retrieving ticket IDs: {e}")

    return ticket_ids




#options.add_argument(f"--user-data-dir={CHROME_USER_DATA_DIR}")


# -------------------------------------------------------------------
# Main driver (example)
# -------------------------------------------------------------------
def main():
    #if not check_running_session():
    #    open_profile()
    #    time.sleep(3)  # Allow time for the browser to start
    #driver = get_chrome_driver()

    # Process each ticket
    drivers = []  # List to store driver instances

    new_driver = webdriver.Firefox()

    drivers.append(new_driver)
    new_driver.get("https://redhat.service-now.com/now/nav/ui/classic/params/target/x_redha_red_hat_tr_x_red_hat_training_list.do%3Fsysparm_query%3Dassigned_toDYNAMIC90d1921e5f510100a9ad2572f2b477fe%255EstateIN2%255Eactive%253Dtrue%255Eshort_descriptionLIKEFeedback%3A%26sysparm_first_row%3D1%26sysparm_view%3D")

    # Process the ticket in the new tab
    login_snow(new_driver)
    time.sleep(10)
    #login_rol(new_driver)

#    snow_info = {
#        "snow_id": "1234567890",
#        "Description": "Cannot build http-client image, cannot pull source image: Error: creating build container: initializing source docker://registry.lab.example.com/rhel9/php-82:1-15: reading manifest 1-15 in registry.lab.example.com/rhel9/php-82: unauthorized: access to the requested resource is not authorized",
#        "Course": "RH199",
#        "Version": "1.0",
#        "URL": "https://www.redhat.com",
#        "Chapter": "1",
#        "Section": "1",
#        "Title": "Test Title",
#        "RHNID": "test@redhat.com"
#    }
#
#    #jira_login(new_driver)
#    time.sleep(4)
#    analysis_response_json =  {
#            "analysis": "The student's feedback indicates that the 'labs declarative-review' and 'declarative-kustomize' sections are failing at waiting for the cluster phase. To analyze this, we need to examine the guide text for relevant instructions or commands related to waiting for the cluster phase.",
#            "is_valid_issue": True,
#            "content_issue_location": "The specific location/step where the content issue appears is not provided in the guide text excerpt.",
#            "suggested_correction": "Include explicit commands or steps to wait for the cluster phase, such as 'kubectl wait --for=condition=Ready pod --all --timeout=600s' or similar. Ensure proper error handling and retries if necessary.",
#            "confidence": 0.85,
#            "summary": "Student reports failure in waiting for cluster phase during 'declarative-review' and 'declarative-kustomize' labs. Guide text needs to include relevant commands/steps for this process."
#            }
#    search_jira_ticket(new_driver, snow_info)


    snow_tickets = get_ticket_ids(new_driver)
    print(f"[INFO] Found {len(snow_tickets)} tickets to process.")

    for ticket_id in snow_tickets:
        try:
            # Create a new Firefox driver instance that opens a new browser window
            new_driver = webdriver.Firefox()
            new_driver.maximize_window()
            drivers.append(new_driver)

            new_driver.get(f"https://redhat.service-now.com/surl.do?n={ticket_id}")

            # Process the ticket in the new tab
            login_snow(new_driver)
            time.sleep(5)
            check_cookies(new_driver)
            time.sleep(5)

            print(f"\nProcessing ticket {ticket_id}...")
            snow_info = get_snow_info(new_driver, ticket_id)
            handle_snow_ticket(new_driver, snow_info)
        except Exception as e:
            print(f"[ERROR] Failed to process ticket {ticket_id}: {e}")
            continue

    # driver.quit()  # close the browser if desired
    time.sleep(1000000000)


if __name__ == "__main__":
    main()


