#!/usr/local/bin/python3
"""
First implementation for processing SNOW tickets that are specifically about typos
in Student Guides using Selenium and local AI (Ollama).
"""

import os
import re
import subprocess
import time
import json
from selenium import webdriver
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.by import By
import requests

# -------------------------------------------------------------------
# Configurable constants for local paths, etc.
# -------------------------------------------------------------------
LOCAL_CLONE_DIRECTORY = "{{ playbook_dir }}/files/"
GUIDE_SUBDIR = "content"
OLLAMA_COMMAND = "/usr/local/bin/ollama"  # Adjust if your Ollama binary is named differently
CHROME_DEBUG_PORT = 9123    # Example local Chrome debugger port for your session
CHROME_USER_DATA_DIR = "{{ ansible_env.HOME}}/.config/google-chrome/snow-typos"

counter = 1
# Prints the current step
def step(step_str, patience=1):
    global counter
    print(f"Step {counter}: {step_str}")
    print('-' * 40)
    counter += 1
    time.sleep(patience)

# -------------------------------------------------------------------
# Browser session helpers
# -------------------------------------------------------------------
def open_profile():
    """
    Opens a new Google Chrome session with remote debugging enabled,
    using the designated user data directory.
    """
    os.popen('google-chrome --remote-debugging-port=' + str(CHROME_DEBUG_PORT) +
             ' --user-data-dir=' + CHROME_USER_DATA_DIR + ' &')

def check_running_session():
    """
    Checks if a Google Chrome session is already running by looking for the user data directory
    and the designated debugging port.
    Returns the PID if found, or 0 otherwise.
    """
    pid = os.popen("ps -ef | grep '" + CHROME_USER_DATA_DIR +
                   "' | grep " + str(CHROME_DEBUG_PORT) +
                   " | grep -v grep | head -n1 | awk '{print $2}'").read().strip()
    if pid:
        return int(pid)
    else:
        return 0


# -------------------------------------------------------------------
# Example function to call Ollama locally with your query/prompt
# -------------------------------------------------------------------
# You can change the model to one available on your system.
OLLAMA_MODEL = "granite3.1-dense:8b"
OLLAMA_MODEL = "llama3.2:latest"


def askOllama(prompt: str) -> str:
    """
    Runs Ollama locally with the given prompt and returns the response text.
    Make sure 'ollama' is installed on your system and in PATH.
    """
    try:
        # Use 'ollama run <model> "<prompt>"'
        result = subprocess.run(
            [OLLAMA_COMMAND, "run", OLLAMA_MODEL, prompt],
            capture_output=True,
            text=True
        )
        return result.stdout.strip()
    except Exception as e:
        print(f"[ERROR] Could not run Ollama: {e}")
        return ""


def ask_gpt4_mini(prompt: str) -> str:
    """
    Calls the GPT-4 Mini API with the given prompt and returns the response.
    Uses the API key and URL from the environment variables GPT4_MINI_API_KEY and GPT4_MINI_API_URL.
    """
    import os
    import requests

    api_key = os.getenv("OPENAI_API_KEY")
    api_url = "https://api.openai.com/v1/chat/completions"
    if not api_key or not api_url:
        print("[ERROR] GPT4_MINI_API_KEY or GPT4_MINI_API_URL environment variable not set.")
        return ""
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "gpt-4o-mini",
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 500,
        "temperature": 0.7,
        "top_p": 1
    }
    try:
        response = requests.post(api_url, headers=headers, json=payload)
        response.raise_for_status()
        result = response.json()
        # Adjust the following line if the returned JSON structure differs.
        return result.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
    except Exception as e:
        print(f"[ERROR] GPT-4o-mini API request failed: {e}")
        return ""

# -------------------------------------------------------------------
# Function to set up the Selenium driver for Chrome
# -------------------------------------------------------------------
def get_chrome_driver() -> webdriver.Chrome:
    """
    Returns a Selenium Chrome WebDriver configured to use the
    remote debugging port and user data directory.
    """
    options = webdriver.ChromeOptions()
    options.add_argument("--ignore-certificate-errors")
    options.add_argument("--window-size=1600,1200")
    # Attach to our debug port and user data directory
    options.add_experimental_option("debuggerAddress", f"localhost:{CHROME_DEBUG_PORT}")
    options.add_argument(f"--user-data-dir={CHROME_USER_DATA_DIR}")

    try:
        driver = webdriver.Chrome(options=options)
        return driver
    except Exception as e:
        print(f"[ERROR] Unable to start Chrome driver: {e}")
        raise

def switch_to_iframe(driver):
    driver.switch_to.default_content()
    macroponent = WebDriverWait(driver, 3).until(
        EC.presence_of_element_located((By.XPATH, '//*[starts-with(local-name(), "macro")]'))
    )
    shadow_root = driver.execute_script('return arguments[0].shadowRoot', macroponent)
    iframe = shadow_root.find_element(By.CSS_SELECTOR, 'iframe#gsft_main')
    WebDriverWait(driver, 3).until(EC.frame_to_be_available_and_switch_to_it(iframe))


# -------------------------------------------------------------------
# Cookie, login and navigation helpers (integrated from operate-lab.py.j2)
# -------------------------------------------------------------------
def accept_cookies(driver):
    """
    Clicks the cookie accept button and refreshes the page.
    """
    try:
        WebDriverWait(driver, 3).until(
            EC.element_to_be_clickable((By.XPATH, "//a[@class='call'][text()='Agree and proceed with standard settings']"))
        ).click()
        driver.refresh()
    except Exception as e:
        driver.refresh()
        print("[WARNING] accept_cookies failed:", e)

def check_cookies(driver):
    """
    Checks if the cookie consent iframe is present and accepts cookies.
    """
    try:
        WebDriverWait(driver, 2).until(
            EC.frame_to_be_available_and_switch_to_it((By.XPATH, '//iframe[@title="TrustArc Cookie Consent Manager"]'))
        )
        accept_cookies(driver)
        driver.switch_to.default_content()
    except Exception:
        pass


def login(driver):
    """
    Logs into the course website based on the lab_environment setting.
    The values for credentials should be passed in from Ansible.
    """
    step("Login into RHLS production environment")
    try:

        check_cookies(driver)
        WebDriverWait(driver, 2).until(EC.element_to_be_clickable(
            (By.XPATH, "/html/body/div[1]/main/div/div/div[1]/div[2]/div[2]/div/section[1]/form/div[1]/input"))).send_keys("{{ rh_username }}@redhat.com")
        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="login-show-step2"]'))).click()

        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="rh-sso-flow"]'))).click()

        # RH SSO
        WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="username"]'))).send_keys("{{ username }}")
        WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="password"]'))).send_keys(str("{{ pin }}").replace('\n', '') + str(os.popen("curl -sL https://sso-rh-login-lx-snow.apps.tools-na100.dev.ole.redhat.com/get_otp").read().replace('\n', '')))
        WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="submit"]'))).click()

        wait_for_site_to_be_ready(driver)
    except:
        print("Login failed")

def wait_for_site_to_be_ready():
    try:
        check_cookies(driver)
        print("Site is ready")
    except Exception as e:
        check_cookies(driver)
        print("[ERROR] Login failed:", e)

def wait_for_site_to_be_ready(driver, lab_environment):
    """
    Waits for the main site element to be clickable before proceeding.
    """
    try:
        check_cookies(driver)
        if lab_environment in ["rol", "china"]:
            WebDriverWait(driver, 2).until(
                EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/div[1]/header/div[2]/div/nav[2]/button[4]'))
            )
        elif lab_environment == "rol-stage":
            WebDriverWait(driver, 2).until(
                EC.element_to_be_clickable((By.XPATH, '//*[@id="avatar"]'))
            )
        print("Site is ready")
    except Exception as e:
        time.sleep(0.5)
        check_cookies(driver)
        wait_for_site_to_be_ready(driver, lab_environment)

def select_lab_environment_tab(driver, tab_name):
    """
    Selects the appropriate tab on the course page.
    """
    if tab_name == "index":
        tab_id = "1"
    elif tab_name == "course":
        tab_id = "2"
    elif tab_name == "lab":
        tab_id = "8"
    try:
        WebDriverWait(driver, 60).until(
            EC.element_to_be_clickable((By.XPATH, f'//*[@id="course-tabs-tab-{tab_id}"]'))
        ).click()
        time.sleep(0.1)
        lab_environment_tab_status = WebDriverWait(driver, 30).until(
            EC.element_to_be_clickable((By.XPATH, f'//*[@id="course-tabs-tab-{tab_id}"]'))
        ).get_attribute("aria-selected")
        if lab_environment_tab_status != "true":
            time.sleep(0.1)
            select_lab_environment_tab(driver, tab_name)
    except Exception as e:
        print("[WARNING] Lab environment tab not selected successfully. Retrying...", e)
        check_cookies(driver)
        time.sleep(2)
        select_lab_environment_tab(driver, tab_name)


# -------------------------------------------------------------------
# Function to classify a SNOW ticket using an LLM
# -------------------------------------------------------------------
def classify_ticket_llm(description: str) -> dict:
    """
    Classifies a SNOW ticket using an LLM, returning a dict like:
    {
      "student_feedback": str,
      "most_defining_issue_keywords": list[str],  # List of 3 keywords
      "is_content_issue_ticket": bool,
      "is_environment_issue": bool,
      "confidence": float,
      "summary": str
    }
    """
    step("Classifying ticket using LLM")
    
    json_example = '{"student_feedback":"", "most_defining_issue_keyword":["md5sum", "output", "command"], "is_content_issue_ticket":true,"is_environment_issue":false, "confidence":0.9,"summary":"The md5sum command drops a different output than the one expected."}'
    prompt = f"""
Classify the user's feedback regarding a Red Hat Training course, a typo can be a mismatch or inconsistency between the user's complaint and the text in the guide. Return JSON with fields:
- student_feedback (the user's feedback)
- most_defining_issue_keyword (a list of 3 substantive words (not verbs or adjectives) from the *User feedback* that are the most unique and less generic that will be used to grep the guide text)
- is_content_issue_ticket (true/false)
- is_environment_issue (true/false)
- confidence (a float from 0.0 to 1.0)
- summary (in a short sentence)

User feedback:
\"\"\"{description}\"\"\"

Reply in JSON only, no extra text.
For example:
{json_example}
"""
    #response = ask_gpt4_mini(prompt)
    global classifying_response
    classifying_response = askOllama(prompt)
    print("[GPT4-mini response regarding typos]:\n", classifying_response)
    # Then parse JSON via Python. Temporary fallback if there's an error:
    try:
        return json.loads(classifying_response)
    except:
        print("[ERROR] Could not parse JSON from LLM. Full response:", classifying_response)
        return {
            "is_content_issue_ticket": False,
            "is_environment_issue": False,
            "confidence": 0.0,
            "summary": "",
            "most_defining_issue_keyword": []
        }


# -------------------------------------------------------------------
# Function to ensure that the course repository is available
# -------------------------------------------------------------------
def ensure_course_repo(course_id: str) -> str:
    """
    Ensures that the repository for the specified course is cloned.
    The repository URL is constructed as:
       git@github.com:RedHatTraining/<base_course>.git
    where <base_course> is extracted from course_id.
    If the repository is not present in LOCAL_CLONE_DIRECTORY, it is cloned.
    If it exists, a 'git pull' is performed.
    Returns the repository directory path.
    """
    step("Ensuring course repository is available")
    base_course = re.split(r"-", course_id)[0]
    base_course = re.split(r"ea", base_course)[0]
    repo_dir = os.path.join(LOCAL_CLONE_DIRECTORY, base_course)
    repo_url = f"git@github.com:RedHatTraining/{base_course.lower()}.git"
    if not os.path.exists(repo_dir):
        print(f"[INFO] Repository not found at {repo_dir}. Cloning from {repo_url} ...")
        clone_cmd = f"git clone {repo_url} {repo_dir}"
        result = os.system(clone_cmd)
        if result != 0:
            print(f"[ERROR] Failed to clone repository: {repo_url}")
    else:
        print(f"[INFO] Repository found at {repo_dir}. Pulling latest changes...")
        pull_cmd = f"cd {repo_dir} && git pull"
        os.system(pull_cmd)
    return repo_dir


# -------------------------------------------------------------------
# Function to extract the lab script name from the course page
# -------------------------------------------------------------------
def get_section_info(driver, course_url: str, is_even_section: bool) -> str:
    """
    Navigates to the course URL, performs login if necessary,
    and extracts the lab start command from the page.
    Returns the lab script name specified in a command such as 'lab start <script name>'.
    """
    step("Extracting relevant information from section")
    try:
        driver.execute_script("window.open()");
        driver.switch_to.window(driver.window_handles[-1]);
        driver.get(course_url)
        check_cookies(driver)
        # Optionally, if login is enforced here, call:
        # login(driver, lab_environment, rh_username, username, pin, github_username, github_password)
        # You can pass the required credentials from Ansible variables.
        #login(driver)

        time.sleep(4)  # Allow time for the page to load completely

        # If your course page has tabs, you might need to select the "course" tab
        select_lab_environment_tab(driver, "course")

        # TODO: for comp-review might not be even, but last items of the chapter or last chapter's sections
        # It is a guided exercise
        if not is_even_section:
            h3_subsection = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.XPATH, f"//h3/a[not(contains(@id, 'objectives'))]//.."))
            ).text
            print(f"[INFO] Found relevant section info: {h3_subsection}")
            return h3_subsection

        else:
            # Locate an element containing the "lab start" command
            element = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.XPATH, "//*[contains(text(), 'lab start')]"))
            )

            text = element.text
            match = re.search(r"lab start\s+(\S+)", text, re.IGNORECASE)
            if match:
                lab_script_name = match.group(1)
                print(f"[INFO] Extracted lab script name: {lab_script_name}")
                return lab_script_name
                            
    except Exception as e:
        print(f"[ERROR] Could not retrieve lab start script name from {course_url}: {e}")
        return ""


# -------------------------------------------------------------------
# Function to fetch relevant text from the local course repository
# -------------------------------------------------------------------
def fetch_local_guide_text(section_info: str, repo_dir: str = None) -> str:
    """
    Fetches the relevant guide text from the course repository.
    If repo_dir is not provided, it is constructed from the course_id.
    Uses lab_script_name to grep for the correct adoc file.
    """

    try:
        if repo_dir is not None and section_info != "":            
            file_dir = f"grep -ri '{section_info}' {repo_dir}/{GUIDE_SUBDIR} | grep -E 'ge.adoc|lecture.adoc|review.adoc|lab.adoc' | head -n1 | cut -d ':' -f1"
            print(f"[INFO] files that match the section info: {file_dir}")

            try:
                content_file = subprocess.check_output(file_dir, shell=True).decode().strip()
                with open(content_file) as file:
                    content_file = file.read().strip()
            except Exception as e:
                print(f"[ERROR] Could open file {content_file}: {e}")
                return ""
                
            print(f"[INFO] Content file path: {content_file}")
            
            return content_file.strip()
        else:
            print("[INFO] Not enough information to fetch local guide text.")
            return ""
    except Exception as e:
        print(f"[ERROR] Could not fetch local guide text: {e}")
        return ""


# -------------------------------------------------------------------
# Put everything together in a main workflow for a single SNOW ticket
# -------------------------------------------------------------------
def handle_snow_typo_ticket(driver: webdriver.Chrome, snow_id: str):
    """
    Processes a SNOW ticket by:
    1. Navigating to the SNOW record.
    2. Parsing the description.
    3. Checking via LLM if it's a typo ticket.
    4. If so, ensuring the course repository is available, fetching the lab start script name
       from the course page (using the URL in the ticket), and then fetching the guide text,
       then invoking further LLM analysis.
    """
    step("Navigating to the SNOW ticket")
    # 1. Navigate to the SNOW ticket
    snow_url = f"https://redhat.service-now.com/surl.do?n={snow_id}"
    driver.execute_script("window.open()");
    driver.switch_to.window(driver.window_handles[-1]);
    driver.get(snow_url);
    time.sleep(3)  # Simplified wait for example

    # 2. Parse the SNOW ticket description
    try:
        switch_to_iframe(driver)
        description_element = WebDriverWait(driver, 5).until(
            EC.presence_of_element_located(
                (By.XPATH, '//*[@id="sys_original.x_redha_red_hat_tr_x_red_hat_training.description"]')
            )
        )
        description = description_element.get_attribute("value")
    except Exception as e:
        print(f"[ERROR] Could not read SNOW ticket description: {e}")
        return

    # 3. Extract user issue from the description
    user_issue = re.search(r"Description:\s*(.*?)\s*Copyright", description, re.DOTALL).group(1).strip()

    # 4. Check if it's a "typo" ticket
    data = classify_ticket_llm(user_issue)
    if not data.get("is_content_issue_ticket", False):
        print(f"[INFO] This SNOW ticket {snow_id} doesn't appear to be a simple 'typo' issue.")
        return

    print(f"[INFO] SNOW ticket {snow_id} is recognized as a 'typo' feedback ticket.")

    # 5. Extract course id, course URL from the description
    course_id = ""
    course_match = re.search(r"Course:\s*([A-Za-z0-9\-]+)", description)
    if course_match:
        course_id = course_match.group(1)

    course_url = ""
    url_match = re.search(r"URL:\s*(https?://\S+)", description)
    if url_match:
        course_url = url_match.group(1)
        chapter_and_section = re.search(r'pages/(ch\d+s\d+)', course_url).group(1) if re.search(r'pages/(ch\d+s\d+)', course_url) else ""
        # Extract section number and determine if it's even or odd
        is_even_section = False
        if chapter_and_section:
            section_match = re.search(r's(\d+)', chapter_and_section)
            if section_match:
                section_num = int(section_match.group(1))
                is_even_section = (section_num % 2 == 0)
                print(f"[INFO] Section number {section_num} is {'even' if is_even_section else 'odd'}")

    if course_id:
        repo_dir = ensure_course_repo(course_id)

    # 6. Retrieve the lab start script name from the course page
    section_info = ""
    if course_url != "":
        section_info = get_section_info(driver, course_url, is_even_section)

    # 7. Ensure the repository is available and fetch local guide text using the lab script name
    local_guide_text = ""
    if section_info != "":
        local_guide_text = fetch_local_guide_text(section_info, repo_dir)
        print(f"[INFO] Local guide text: {local_guide_text}")
    else:
        print("[INFO] No course ID or lab script name found in the SNOW ticket.")
        return

    if data.get("is_content_issue_ticket", False):
        print(f"[INFO] This SNOW ticket {snow_id} is recognized as a 'content' issue feedback ticket.")
    else:
        print(f"[INFO] This SNOW ticket {snow_id} doesn't appear to be a simple 'content' issue.")
        return

    # 8. Construct the prompt for advanced LLM analysis and call GPT4-mini
    # 9. Perform a grep search for the most defining issue keyword in the local guide text
    most_defining_issue_keywords = data.get("most_defining_issue_keywords", ["", "", ""])
    grep_result = ""
    if most_defining_issue_keywords:
        grep_results = []
        for keyword in most_defining_issue_keywords:
            if keyword != "":
                grep_command = f"echo '{local_guide_text}' |grep -A3 '{keyword}'"
                try:
                    result = subprocess.run(grep_command, shell=True, text=True, capture_output=True).stdout
                    grep_results.append(result)
                    print(f"[INFO] Grep result for keyword '{keyword}':\n{result}")
                except subprocess.CalledProcessError as e:
                    print(f"[ERROR] Grep command failed: {e}")
        
        grep_result = "\n".join(grep_results)
        print(f"[INFO] Grep result:\n{grep_result}")
    else:
        print("[INFO] No defining issue keyword found in the LLM response.")

    analyze_content_issue(user_issue, grep_result)
    print("[LLM response regarding typos]:\n", typo_detected_response)
    print("[INFO] Based on the AI result, proceed with your next steps here...")
    return

def analyze_content_issue(user_issue: str, guide_text: str) -> str:
    """
    Analyzes a potential content issue by comparing user feedback with guide text.
    
    Args:
        user_issue: The user's reported issue/feedback
        guide_text: Relevant excerpt from the guide
        
    Returns:
        str: JSON response from LLM analysis
    """
    json_example = '''{
            "thinking": "think in this value step by step, compare the student's feedback with the guide text, and provide a detailed analysis of the issue",
            "is_content_issue_ticket": true,
            "content_issue_location": "a short description or excerpt of the location/step where the content issue appears",
            "suggested_correction": "a brief suggestion for correction if applicable; otherwise an empty string",
            "confidence": "a float value between 0 and 1 indicating your confidence",
            "summary": "a short summary of your analysis"
            }'''

    prompt_text = f"""
We have a student who reported an issue with the guide text. The student's complaint is:
"{user_issue}"

Below is an excerpt of the guided exercise text:
--------------------------------
{guide_text}
--------------------------------

Please analyze the guided exercise and determine if there is a typographical error or textual mismatch that could be causing the student's issue.
Your analysis must consider headings, task summaries, instructions, and any text content that might be inconsistent with the complaint.

Return your analysis in exactly the following JSON format without any extra text:

{json_example}

Do not include any explanations or markdown formatting outside the JSON object.
"""
    #response = ask_gpt4_mini(prompt_text)
    global typo_detected_response
    typo_detected_response = askOllama(prompt_text)
    return typo_detected_response

# -------------------------------------------------------------------
# Main driver (example)
# -------------------------------------------------------------------
def main():
    #if not check_running_session():
    #    open_profile()
    #    time.sleep(3)  # Allow time for the browser to start
    #driver = get_chrome_driver()
    driver = webdriver.Chrome()
    driver.get("https://rol.redhat.com/")
    login(driver)
    time.sleep(5)
    check_cookies(driver)
    time.sleep(5)

    # List of SNOW tickets to process
    snow_tickets = [
        "RHT2315790",
        "RHT2319171",  # Example ticket
        "RHT2332936"
    ]

    # Process each ticket
    for ticket_id in snow_tickets:
        print(f"\nProcessing ticket {ticket_id}...")
        handle_snow_typo_ticket(driver, ticket_id)

    # driver.quit()  # close the browser if desired
    time.sleep(500)
if __name__ == "__main__":
    main()
